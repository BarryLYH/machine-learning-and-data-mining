{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom sklearn.model_selection import train_test_split",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9d20aa11fa62597c1fcb9892012d9822cb20eac1"
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(r'../input/train.csv',dtype = np.float32)\n\ntargets = train.label.values\nfeatures = train.loc[:,train.columns != \"label\"].values/255\n\nfeatures_train, features_test, targets_train, targets_test = train_test_split(features, targets, test_size = 0.2, random_state=42)\n\nfeaturesTrain = torch.from_numpy(features_train)\ntargetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n\nfeaturesTest = torch.from_numpy(features_test)\ntargetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long\n\nprint(featuresTrain[1].shape, featuresTest.shape)\nprint(targetsTrain.shape, targetsTest.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f43c4c93ca6ba1a1d95641889c538b6c097ccd7c"
      },
      "cell_type": "code",
      "source": "#Create CNN model\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\n\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=0)\n        self.cnn2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=0)\n        self.cnn3 = nn.Conv2d(32, 64, 3)\n        self.cnn4 = nn.Conv2d(64, 64, 3)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2)\n        self.dropout = nn.Dropout2d(p=0.2)\n        self.fc1 = nn.Linear(4*4*64, 70)\n        self.fc2 = nn.Linear(70,10)\n        \n    def forward(self, x):\n        out_con1 = self.cnn1(x)\n        out_relu1 = self.relu(out_con1)\n        out_con2 = self.cnn2(out_relu1)\n        out_relu2 = self.relu(out_con2)\n        \n        out_pool1 = self.maxpool(out_relu2)\n        \n        out_con3 = self.cnn3(out_pool1)\n        out_relu3 = self.relu(out_con3)\n        out_con4 = self.cnn4(out_relu3)\n        out_relu4 = self.relu(out_con4)\n        \n        out_maxpool = self.maxpool(out_relu4)\n        out_dropout2 = self.dropout(out_maxpool)\n        \n        out = out_dropout2.view(out_dropout2.size(0), -1)\n        out = self.fc1(out)\n        \n        return self.fc2(out)\n\nbatch_size = 100\n#interations = 2500\nepochs = 5000\n#print(epochs)\ntrain = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\ntest = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n\ntrain_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\ntest_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n\nmodel = CNNModel()\nmodel.cuda()\n\nerror = nn.CrossEntropyLoss()\n\nlearning_rate = 0.0001\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, betas=(0.9, 0.999))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7e990fd8661b3e0fb9f8faae77a813dd94a9a987"
      },
      "cell_type": "code",
      "source": "def adjust_learning_rate(optimizer):\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = param_group['lr'] * 0.9\n\n\ncount = 0\n#loss_list = []\n#iteration_list = []\n#accuracy_list = []\nfor epoch in range(1, epochs+1):\n    for i, (images, labels) in enumerate(train_loader):\n        train = Variable(images.view(batch_size, 1, 28, 28)).cuda()\n        labels = Variable(labels).cuda()\n        \n        optimizer.zero_grad()\n        \n        outputs = model(train)\n        \n        loss = error(outputs, labels).cuda() \n        loss.backward()\n        optimizer.step()\n        count += 1\n    if epoch % 10 == 0:\n        correct = 0\n        total = 0\n        for images, labels in test_loader:\n            test = Variable(images.view(batch_size,1,28,28)).cuda()\n            labels = Variable(labels).cuda()\n            outputs = model(test)\n            predicted = torch.max(outputs.data, 1)[1].cuda().data.squeeze()\n            total += len(labels)\n            correct += (predicted == labels).sum()  \n        accuracy = 100 * float(correct) / float(total)\n\n        #loss_list.append(loss.data)\n        #iteration_list.append(count)\n        #accuracy_list.append(accuracy)\n        print('Epoch: {}  Loss: {}  Accuracy: {} %'.format(epoch, loss.data[0], round(accuracy, 7)))       ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ecf15058072243b19c4b1a6d0dbf56261194dc46"
      },
      "cell_type": "code",
      "source": "test_csv = pd.read_csv(r'../input/test.csv',dtype = np.float32)\ntestfeatures = test_csv.loc[:,test_csv.columns != \"label\"].values/255\n\nfeaturestest = torch.from_numpy(testfeatures)\n\nans_arr = []\nfor i, images in enumerate(featurestest):\n    images = Variable(images.view(-1, 1, 28, 28)).cuda()\n    outputs = model(images)\n    #print(outputs.size())\n    _, predicted = torch.max(outputs.data, 1)\n    ans_arr.append(predicted)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "_uuid": "b31aaeef7d211e8e4e17f7ee2d28f04703c5b506"
      },
      "cell_type": "code",
      "source": "ans_arr = [int(x) for x in ans_arr]\ndf_preds = pd.DataFrame()\ndf_preds['ImageId'] = pd.Series([i+1 for i in range(28000)])\ndf_preds['Label'] = pd.Series(ans_arr)\ndf_preds.to_csv(\"base.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}